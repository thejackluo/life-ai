Comprehensive Meeting Notes: From AI World Generation to Building a Memory-Based GameMeeting Date: [Following the previous planning session]
Duration: Approximately 1 hour 20 minutes
Participants: Jack and Arman (collaborator identified by name in this session)
Format: Virtual via ZoomIntroduction: A Shift Toward Game DevelopmentThis second meeting marked a dramatic pivot from the previous session's exploration of music AI and productivity apps. Jack and Arman had clearly done some thinking between sessions, and this conversation opened with immediate action—Jack pulling up something exciting to show. "Let me close a few things," he said, navigating through windows. What followed was a demonstration that would set the entire tone for their hackathon project: Google's Genie 3, a frontier model for generating interactive 3D worlds.The energy was different from the previous meeting. Where the first session had been exploratory and research-heavy, weighing different possibilities, this conversation had momentum from the start. They were seeing cutting-edge technology that sparked immediate inspiration, and by the end of the meeting, they would have a concrete plan for what to build.The Genie 3 Revelation: World Generation That Actually WorksJack loaded up a demo video for Genie 3, Google's new world generation model. "What you're seeing are not games or videos. They're worlds," the narrator explained. The technology was striking: you could use natural language to generate interactive 3D environments and explore them in real time, all from a single text prompt. These weren't pre-built simulations—everything was being generated live as you explored.What made Genie 3 particularly impressive was its "world memory." Environments stayed consistent as you moved through them. The demo showed someone painting on a wall in the generated world, looking away to explore other areas, then returning to find the painting still there. Actions persisted. The world remembered. You could also trigger "promptable events"—adding new elements like other characters, vehicles, or unexpected objects on the fly.The applications went beyond gaming. The narrator described potential uses in embodied AI research, training robotic agents in simulated environments before deploying them in the real world, simulating dangerous scenarios for disaster preparedness and emergency training. "World models can open new pathways for learning, agriculture, manufacturing, and more," the video concluded.Jack's reaction was visceral. "This field of research is like probably some of the most interesting stuff you can research," he said, clearly energized. "I'm kind of jealous of the people who was doing research in this because this is so fun." Arman agreed, noting that Google was always doing really cool research, especially with creative things. The technology felt like a glimpse into the future—not just incremental improvement, but genuinely new capabilities.The Demo Problem and Future PotentialOf course, there was a catch. "Unfortunately, you cannot play or use this model," Jack noted with disappointment. He'd tried to find a playable demo when he first saw Genie 3, but Google hadn't released one. "It's like they have videos. They try to show you what it's like. But they don't have anything that you can actually play, which is the cool part, right?" The best bet for hands-on experience would be attending a Google conference if they demonstrated it there.Despite the lack of public access, Jack could already envision the trajectory. "I can actually imagine game scene like this in five years," he said. The main technical hurdle was the flickering and artifacts in the video generation, but once that was solved? "A game like this is so powerful. I honestly call it like a super game." He explained what he meant: it would be more creative and expansive than anything traditional game studios could produce. If you could create games like this, you'd "overtake almost all the game studios."The killer feature wasn't just the generation quality—it was the personalization. "Everyone has a different Cyberpunk because of how the actions they've taken," Jack mused, imagining a world where every player's experience diverged based on their choices, with the AI generating unique content for each path. Arman compared it to GTA, "except you can go into any of the buildings and explore." That was exactly it—infinite, explorable, personalized worlds.The Genie 3 demonstration had fundamentally shifted their thinking. Suddenly, game creation didn't seem like a distant dream requiring massive teams and years of development. It felt possible, even accessible, if you had the right AI tools.Discovering the Game Creation Platform: AI Agents Building GamesStill riding the excitement from Genie 3, Jack navigated to a game creation platform he'd apparently found. This wasn't Google's technology, but something currently available. He pulled up the interface and started exploring, with Arman watching along.The platform offered something remarkable: you could describe a game concept, and AI agents would collaboratively build it. Jack decided to test it immediately. "Create a game for Arman and Jack," he began typing. "RPG game. A cyberpunk setting in 2037. Whereas a bunch of robots that are very intelligent but also emotional. They're trying to figure out their human side of things. The game should be challenging. It should be platformer. And there should also be NPCs you can talk to. It should be a deep game that is branching where's different endings."The platform required sign-in, which Jack did without hesitation. "Any game creation, I will sign in immediately," he declared. What appeared next was surprising: a comprehensive list of game templates. Visual novels, character simulations, dungeon crawlers, shooting games, rhythm games, platformers, even 3D open world options. "I did not expect there to be so many," Jack said, genuinely surprised by the breadth of options.They scrolled through the templates together, commenting on each. Some reminded them of classic games—the shooting arcade template looked like Crossy Road, there was a Flappy Bird clone, various action-focused options. "Honestly, the most curious one is always obviously the 3D one," Jack noted, and Arman agreed. The 3D open world template was the most ambitious and interesting.Creating Arman's Character: From Prompt to AssetJack had an idea to make this more personal. He had a cyberpunk world he'd been developing called "Liminal," complete with visual assets in a consistent style. "I need to generate a picture for you as well," he told Arman. "Can you just give me like a prompt I can like use? I can generate like a thing for you? It could be a picture and also like just like a prompt about yourself so I can like generate like an image for you."What followed was a fascinating exercise in self-description. Arman used voice-to-text to create his character prompt, speaking directly and honestly: "Arman is a 22-year-old computer science student in his senior year and he is trying to become a cracked individual in all aspects of his life. So he's currently playing around with different startup ideas. In his free time, he likes to go to the gym and he also has some random hobbies like making beats, creating shirt designs, and going to coffee shops."He continued building out the character: "Arman is a good listener. He's thoughtful. He values his friends and family. He likes sports—soccer, basketball, pickleball. He did diving in high school. So he likes a lot of random sports." Then came a moment of vulnerability: "Arman is single. He hopes to one day reach his true potential. So he kind of knows that deep down maybe he'll never reach it, but he does his very best to do so."The final touch was philosophical: "And to be honest, he kind of views the world as a game. And there's like infinite possibilities in games. So for him, he wants to complete all the side quests and maybe even take over the entire Earth. Maybe that's one of the side quests."Jack listened to all of this and then offered something unexpected—not just acceptance of the prompt, but encouragement. "One thing I think you can do amazing things, actually. Don't have to limit yourself and do some crazy stuff if you want. That's something I've realized. Anyone can do like really, really cool stuff. So don't limit yourself."He elaborated on this philosophy, tying it to a blog post he'd written about success that very day. "The big idea is that success is like three things, right? There is your hard work, which I definitely think you have. There is leverage, which most people don't have. That's something that I think most people should work on. And then there is also going to be luck, right, which you cannot control."Jack's point was that Arman already had the foundation—the hard work, the talent. What he needed was leverage: "People who can like, you know, see your potential and help you, you know, get to the next step, right? Maybe through like an investment, maybe through like, you know, an introduction, things like that. You don't lack talent compared to the top people and the most successful people out there."This was more than just friendly encouragement—it was Jack articulating a worldview about potential and opportunity, about how success happens not just through individual effort but through connections and strategic positioning. Arman appreciated it: "For sure, bro. Appreciate that."Musical Interlude: Suno V5 Generates "Echoes of Arman"While waiting for the character generation to process, Jack decided to test something else: Suno's brand new V5 model for music generation. He mentioned that he actually had an interview scheduled with Suno but hadn't gotten around to scheduling it yet. This was the latest and most advanced version of their music AI, and Jack was eager to see what it could do.He fed in information about Arman's musical tastes—rap, Japanese folk, jazz, city pop—and let the model generate. What came out was genuinely impressive. The song was titled "Echoes of Arman," and as they listened, the quality was striking. "City lights dance like fireflies, the saxophone hums where the skyline lies, whispers of jazz in the smoky air, coda string pulls dreams from despair," the generated lyrics went, over a smooth, cohesive instrumental that actually captured the fusion of genres Arman had mentioned."I'm impressed," Jack said simply, listening to the full track. "I want to buy the premium because of this." He played another version to compare it with the previous V4 model. "I think 5 is much higher quality just in general," he concluded. The V5 output had better vocal clarity, more natural phrasing, and a more polished overall production quality. Even the earlier versions were good—"I can listen to this," Jack noted about a V4 track—but V5 represented a clear step forward.Arman was struck by something deeper. "It makes me question the future of music, honestly," he said thoughtfully. "Because I feel like the music industry is already designed to be formulized. So like, this is just taking one step further and applying formulas in tech. And no more humans." It was a prescient observation about what happens when an already somewhat formulaic industry gets access to AI that can execute those formulas perfectly.The music generation was proceeding in parallel with the character generation. They could see different AI agents working on creating assets for their game, even displaying what looked like a chat between agents as they collaborated. "They're talking to each other," Jack observed with fascination. "And they're motivating each other. Oh my God. What?" It was unclear whether this agent chat was real collaboration or just theater for the user, but either way, it demonstrated sophisticated orchestration of multiple AI systems.The Game Reveals: A Playable 3D Cyberpunk WorldAfter all the generation and waiting, the moment arrived: the game was ready to play. Jack loaded it up, both of them excited to see what had been created. What appeared on screen was a fully playable 3D cyberpunk environment with a clear objective: "Grand Van Heist—Steal the cyan and black van under the neon-lit overpass near Eastway No Market. Be aware of patrolling drones and bypass the security lock before driving into the safe house."The game worked. Jack could move, fire, jump, punch. There were NPCs walking around—some aggressive, some neutral. The controls were responsive, if basic. The most impressive moment came when Jack approached a vehicle. "Steal this," he said, hitting the interact button. "Oh my God. You can. What?" The car actually worked. He could drive it through the cyberpunk streets, with physics that felt reasonably realistic.They completed the first quest by stealing the van. New objectives appeared: hunt down the "Crimson Hunters," collect money, explore the warehouse district. Each quest led naturally into the next. The world had coherent geography, persistent NPCs, functional game mechanics. "For a first AI-generated game, I'm impressed," Jack said, genuinely surprised by how well it worked.There were limitations, of course. The game didn't incorporate the visual assets Jack had prepared—the character images and style references didn't make it into the final product. The graphics were functional but not spectacular. Some mechanics were buggy (crashing into cars killed you, which was realistic but maybe not fun). But the fundamental achievement was undeniable: from a text prompt to a playable 3D game with quests, NPCs, drivable vehicles, and combat, all generated in maybe fifteen minutes.Technical Insights: Templates Plus GenerationAs they played, Jack analyzed how the system likely worked. "My guess is they use a template, right, to make to have like preexisting games. And what they do is they generate the assets and the story quest." Arman agreed—it made sense both technically and practically. "I guess it would be really challenging, computationally expensive as well as challenging to create them from ground up."This was a crucial realization: the path to AI-generated games in 2025 wasn't to generate everything from scratch every time. It was to have sophisticated templates with flexible systems, then use AI to populate them with custom content, quests, dialogue, and assets. The template provided the proven game mechanics and technical foundation. The AI provided the creativity and customization.Jack was already thinking about how to leverage this approach. "I'm interested in any attempts to do this and AWS credits to burn," he said. "So if you want to do a game generation, you have $25,000 to burn before anything. I think that's more than enough to generate a good game. And I have to use them up in like a year." The resources were there. The question was how to use them effectively.The Pivot: From 3D Generation to Text-Based InnovationHaving seen what was possible with AI game generation, and understanding the technical limitations, Jack and Arman began to crystallize their own hackathon project direction. The conversation took an interesting turn away from 3D graphics and toward something potentially more innovative: a text-based adventure game with unprecedented depth.Memory-Based Quest Generation: The Core InnovationArman had an insight while watching the game's quest system. "Going back to the message history thing. Maybe objectives could be generated based off of this message history." He explained the concept: if the game had access to your messaging data, it could generate personalized quests based on your actual relationships and activities. "Let's say I play basketball with my one friend a lot. One of the objectives could be play basketball with Devin, my friend. Or the objective could be have dinner with X person."But it went deeper than just recreating activities. "The purpose behind this could also be to get the player to think about the moments that they had with these people. Maybe there's someone that they haven't messaged in a year, but they used to hang out a lot. And one of the objectives that they do in the game would be like, oh, get lunch with X person in the game."The emotional dimension was what made it powerful. "These are kind of generic, but you know what I mean. And then they do that objective, but then also they're kind of like reliving that experience with that person and then they'll be inclined to off game, maybe hit them up and be like, hey man, how you been? I just played this game and I thought about you."Jack caught onto something in Arman's thinking: "I think like a lot of the thematic ideas you've had is about like creating games that bring to fact memories with friends. That's why I've noticed." It was true—whether it was the music project or now this game concept, Arman was consistently interested in technology that strengthened human connections rather than replacing them.Real-World Geography IntegrationBuilding on the memory concept, Arman proposed another layer: real geographic data. "If I'm talking about a specific location, a specific Korean barbecue restaurant, I wonder if there's a way that we'd be able to find the exact coordinates of that location and then be able to generate the world relative to the coordinates of all of the different locations that are mentioned across the database of messages."The idea was elegant: if the AI knew the actual distances between places in your life—your gym, your favorite restaurant, your school, your friends' houses—it could generate a game world that reflected those relationships spatially. "So like if you have a coordinate for your gym, Korean barbecue place, your school, freaking Japan, freaking all the different coordinates, then at least it can kind of relatively show, oh, the gym is here and then the Korean barbecue place kind of here and then the campus is here."Jack immediately saw how to implement this technically. "You use the maps API from Google Maps. What you do is you basically input your location, it's gonna find what is like the one that makes the most sense." There might need to be confirmation for ambiguous locations, but the system could make intelligent guesses based on context. If someone mentioned going to "Lifetime" and their messages indicated they lived in Gainesville, the AI could infer it was the Lifetime gym in Gainesville rather than any other location.The implications were fascinating. "If the game knows like where you're at, then you can like actually create a realistic drive in time—25 miles, for example. And then we can add or minus like, you know, a random amount based on traffic." This could extend to resource management: "Maybe you have to spend like $2 on gas for the drive, right? And then maybe you spent time in the Korean barbecue, you build relationship, but you have to spend money. So now you have basically created real life simulator."Celebrity Integration and Aspirational QuestsJack took the concept even further. "And then if you add like famous characters you want to meet, if you somehow want to meet, for example, Elon Musk, maybe now you can create a quest saying I want to meet Elon Musk. The LLM is going to take real information about Elon Musk and try to figure out a story where perhaps you can meet Elon Musk, or tell you it's genuinely too difficult."This blended the personal with the aspirational. Your game world would contain your actual friends and places, but it could also incorporate your goals and role models, creating narrative bridges between your current reality and your desired future. The game became not just a reflection of your life but a space to explore possibilities."That's powerful. That's very ambitious and powerful, but also a good project," Jack concluded. Arman was on board: "That's so cool." The energy had shifted completely. They weren't just exploring ideas anymore—they were committing to building something specific.Technical Architecture: Building the FoundationWith the concept solidified, Jack began whiteboarding the technical architecture. This wasn't abstract theorizing—he was mapping out the actual data structures and systems they'd need to implement.Node-Based World RepresentationJack started with places. He drew nodes representing different locations, with connections between them representing possible paths or relationships. "You have different nodes, right? This could be two different places. And each node could have some places you can go to, more like events."The key innovation was state management. "We have a state machine that tracks where you're at at this moment. So I can have a state machine that says we're here right now. And then we can migrate here. And then when the story requires you to generate a new node, what you do is you call the model and you generate a new node."This allowed for both structure and flexibility. The world could start with known locations based on message history, but it could expand dynamically as the story required. "We can create notes, and this could expand infinitely as well in all directions." Each new location would be generated with appropriate context, maintaining consistency with what had come before.Characters, Events, and RelationshipsBeyond locations, Jack mapped out the other key entities: characters, events, and relationships. "We can have like a list of different things, right? So we have characters. Each character, we can generate as many as we want. And we can keep going until we have, you know, n characters. And then for each character we can also generate a story and generate infinite stories."Crucially, these elements weren't isolated. "We can also generate relationship between characters and places." A character might have a home base, favorite locations, people they interact with. Events could be tied to specific characters at specific places. "Everything is like generatable, and you can like connect them all together in some ways. I think that's like a good way to represent the state of the world properly."This relational data model was elegant in its simplicity but powerful in its flexibility. You could represent arbitrarily complex social networks and geographic relationships, all while keeping the system manageable and queryable.Starting Simple: Text-Based MVPDespite the ambitious vision, Jack was pragmatic about scope. "Games are fun, right? But I think what we couldn't do in the beginning is we start, we start very simple, and then we go as far as we can." The MVP would be text-based, not graphical. "We can create a text adventure game, which is still pretty cool and honestly very underrated. We can create something dynamic."He referenced AI Dungeon as a point of comparison—a popular text-based AI game, but one with significant limitations. "The only thing it does is it generates stories, but it doesn't have like, you know, coins like money you can earn. It doesn't have too many end conditions. And it's too open-ended for some people."Their version would add structure to the freeform generation. "I actually think a game where it's like options would be better than, you know, a game with like complete free will. I think you should have like a lot of free will, but it shouldn't be like too much that you don't know where to start." This was the goldilocks zone: enough freedom to feel creative and personal, enough structure to be playable and engaging.Once the text-based engine was working—with character stats, memory, relationships, resource management—they could layer on visual elements. "After we have that engine going, we can implement the image and like 2D stuff. And then we can do like environmental generation as well." But even environmental generation could start text-based: "I think we can also start with like a text-based environmental generation. So instead of having like just a text description."The phased approach was smart. Build the core systems first, prove the concept works, then incrementally add sophistication. Don't try to build everything at once and end up with nothing complete.Technical Decisions and Development SetupWith the architecture sketched out, they moved into specific technical decisions about implementation.Engine Selection: Godot Over UnityJack proposed using Godot, an open-source game engine, rather than Unity. He pulled up information about it to show Arman, who hadn't used it before. "The reason why I like this is because, well, first of all, you can use C++. I believe you can use JavaScript as well. They have a 2D engine which is much nicer and easier to use. And it's also open source."The open-source nature was particularly important for their AI integration plans. "I guess you can set up like an AI feature" directly into the engine. Godot's 2D capabilities were strong, making it perfect for a game that would start text-based and potentially evolve into 2D graphics. "The reason why I prefer this over Unity is because it's easy to get into. It's fun to use as well. It's like perfect for hackathon purposes."Jack showed Arman the interface, which was cleaner and less intimidating than Unity's complex environment. "Compared to Unity, which is complex, this is a little bit easier to understand and use." They wouldn't need to wrestle with a steep learning curve—they could start building quickly.Model Strategy: Local and Open SourceA crucial decision was about AI models. Jack was clear: "So me personally, I don't know about you, but I'm curious about open source models more than APIs, because I think with API credits you're using a lot of, you're using a lot of like API credits."The costs could add up quickly with cloud APIs. More importantly, Jack saw educational and technical value in understanding open-source models. "I think if we can, let's try to use open-source models for every memory, dialogue, to voice." Using local models via something like LM Studio meant the game could potentially run offline, without requiring constant API connections."Because if you run like with cloud and API, then you have to be connected to it. But like if we have something like LM Studio where you can run local models, I think might as well run that instead." This also meant fewer restrictions—they wouldn't be constrained by API rate limits or terms of service. Arman confirmed his understanding: "By that also you mean like models that can run locally on the user's machine?" Jack confirmed: "Yes. So it could be offline."This suggested the final application would likely be a desktop application rather than web-based. The trade-off was accessibility (desktop apps require download and installation) versus capability and cost (no ongoing API expenses, more sophisticated local processing).The vMat Planning ToolJack introduced another tool for their development process: vMat, which he described as an AI-assisted planning and architecture tool. "The reason why I mentioned vMat is because it's similar to iterating with AI, but it's more structured. And you have pathways as well. So we can choose to like brainstorm with AI as much as you want or as little as you want."The key advantage was consistency. "It will always like keep a consistent like architecture, feature stores, etc. So like when you actually develop with Cursor or Claude code or any other AI CLIs, then it will always like produce consistent like code that has less bugs."Arman was curious about how it compared to his usual workflow of iterating directly with Cursor. Jack explained that vMat went further than just conversation—it ensured the code met high standards and aligned everything from architecture to design to features, preventing misunderstandings between different AI agents or development phases. "It not only takes everything you say into consideration, it also ensures that the code is completely like, you know, polished and high standard, just as like a good software project."Jack used it for all his projects now and recommended Arman try it for this one. The investment in better planning upfront would pay off in more coherent code and fewer integration headaches later.The Podcast Tangent: Building in PublicWhile Arman was driving home (he'd switched to his phone for the call), the conversation took a lighter turn. Jack made an observation: "We would be great podcast people, honestly." It was true—they'd now spent hours across multiple sessions having engaging, wide-ranging conversations about technology, creativity, and their personal lives.Arman was enthusiastic about the idea. Jack painted the picture: "I think we doing podcasts will be great. We're both very talkative people. I cannot imagine doing like a podcast where someone who's not talkative. So I think it's a conducive environment to do podcast."They discussed the format. An hour seemed like the right length, roughly split into two 30-minute segments like a workout. "Usually if podcasts are scripted or they're impromptu, I think both are honest," Jack noted. "Impromptu is definitely more like genuine. Script is more like professional." But given they didn't have thousands of subscribers yet, impromptu felt appropriate and authentic. "A lot of really cool people, I tell they did a podcast. They don't have that many views, but I still go watch regardless."Arman articulated what made podcasts appealing as a listener: "It's like I'm in a situation where I'm with a group of friends and they are talking and I'm just listening. And I'm not saying anything. I'm just listening to them talk." It was that intimate, casual quality they'd want to capture.Jack had practical resources available. "Obviously we can do online podcasts, but I definitely think in-person podcast is much better. So if you have the chance, I would invite you to come down to Atlanta to do a podcast." The Georgia Tech equipment room had professional podcasting kits he could check out—quality microphones, stands, interfaces. He could also rent cameras with tripods.The production could be straightforward. "All we have to do is we sit, maybe have like a script for questions, and then we just go through the questions and talk. And then we can just edit the video pretty minimally using like, nowadays, like holy shit, you have like AI video editing. It's like ridiculous."This led to a meta-observation about their bubble. "We think that everyone knows about all these AI stuff. It turns out we're in a bubble." Arman asked directly: "Do you think we're in the bubble?" Jack's answer was nuanced: "I think we're in a bubble, but the bubble might actually be real. What that means is it definitely is overvalued. A lot of things are overrated. But the impact and the potential warrants the bubble at least like 50% of it."The AI Dependency QuestionThe conversation about bubbles led to reflection on how dependent they'd become on AI tools. "I think it's hard to imagine life without ChatGPT," Jack admitted. "I can imagine it because I feel like there's a charm encoding without AI. But the thing is, AI is so like indispensable in everything that I think it's hard now to imagine life without AI."Arman drew a parallel: "When I look back to the days of flip phones versus smartphones, same nostalgic feeling I'd get reflecting back, I'm now getting with not having AI back in high school or middle school." The comparison was apt—this was technology that fundamentally changed workflows and capabilities, becoming integrated into daily life in ways that made the previous state difficult to fully recall.Jack acknowledged there was "charm to not using AI"—the satisfaction of figuring things out from scratch. But Arman noted the practical reality: "The time that you spend on a lot of mundane tasks, for example, I remember I used to try and find recipes online and they'd just be filled with ads and filled with bloat. But now I can just ask ChatGPT and it will give me the recipe without any bloat, maybe hallucination, but probably not."Maybe there were generalizations or inaccuracies in AI-generated recipes, but Arman was clear: "I will take that over having to look through a bunch of different websites." Then he added thoughtfully: "But I guess that is part of the charm. Looking through the websites." They both recognized the trade-off—efficiency versus the meandering discovery process, immediate answers versus the journey of research.Development Environment Setup and WorkflowAfter Arman arrived home, they turned to practical setup. Jack had created the GitHub repository and added Arman as a collaborator. They confirmed access was working and began discussing their development workflow for the hackathon.The Cursor Approach: Voice-Driven DevelopmentArman explained his typical hackathon coding approach, which had evolved significantly with AI tools. "First, I would say I try and give as much context as I can to the Cursor about what I want to make. And I will try and have it iterate upon my idea with it and make sure it creates a plan that aligns with my vision."The key was iteration before implementation. He'd go back and forth with the AI to ensure the plan was solid before writing any code. "To the best that I'm able to try and prompt it with as much context as I can." Interestingly, he preferred using voice-to-text for this process. "I especially like to use the voice to text to give it context."Jack was curious about the quality: "How good is the voice to text?" Arman's answer was revealing: "The interesting thing about the performance of voice to text, even if it's inaccurate in like 90% of cases, it doesn't affect the outcome because even if it's inaccurate, the LLM is smart enough to still detect what it means, even if some words are inaccurate or like half the words in like a sentence are inaccurate in some cases."The language model could use surrounding context to infer meaning even from garbled input. "I guess using the surrounding context, it's still able to understand." Of course, sometimes he did need to reprompt if the AI misinterpreted something, "but I guess that's where the plan alignment comes in, going back and forth to make sure that the AI makes a good plan."This was sophisticated prompt engineering—not trying to get perfect input on the first try, but setting up a dialogue where errors could be caught and corrected during the planning phase before they became bugs in the code.Repository and Collaboration SetupJack had the repository ready and was setting up additional collaboration tools. "Let me start a live share session as well," he mentioned, referring to VS Code's Live Share feature that would let them code collaboratively in real-time. This would be essential during the intensive hackathon build period—they could see each other's changes live, debug together, and maintain momentum without constant git push/pull cycles.The technical infrastructure was falling into place: GitHub for version control, Godot as the game engine, local open-source models for AI features, vMat for architectural planning, Cursor for AI-assisted coding, and Live Share for real-time collaboration. They had the resources (Jack's $25,000 in AWS credits, potential OpenAI credits from Princeton), the tools, the concept, and now the setup.
